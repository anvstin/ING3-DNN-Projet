{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Object detection using YOLOv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git submodule update --init --recursive\n",
    "if not os.path.exists('MNIST-ObjectDetection/data'):\n",
    "    %pip install -r MNIST-ObjectDetection/requirements.txt\n",
    "    %cd MNIST-ObjectDetection\n",
    "    !python generate_data.py\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU_NAME =  str(os.popen('nvidia-smi --query-gpu=name --format=csv,noheader').read()).strip()\n",
    "# GPU_COMPUTE_CAPABILITY = str(os.popen('nvidia-smi --query-gpu=compute_cap --format=csv,noheader').read()).strip()\n",
    "# # Remove newlines\n",
    "# GPU_COMPUTE_CAPABILITY = GPU_COMPUTE_CAPABILITY.replace('.', '')\n",
    "\n",
    "# print(f'GPU_NAME: {GPU_NAME}')\n",
    "# print(f'GPU_COMPUTE_CAPABILITY: {GPU_COMPUTE_CAPABILITY}')\n",
    "# # Build using make, enable OpenCV and CUDNN\n",
    "# import re\n",
    "# with open('darknet/Makefile', 'r') as f:\n",
    "#     makefile = f.read()\n",
    "# makefile = re.sub(r'GPU=0', 'GPU=1', makefile)\n",
    "# makefile = re.sub(r'CUDNN=0', 'CUDNN=1', makefile)\n",
    "# makefile = re.sub(r'CUDNN_HALF=0', 'CUDNN_HALF=1', makefile)\n",
    "# makefile = re.sub(r'OPENCV=0', 'OPENCV=1', makefile)\n",
    "\n",
    "# # Remove everything in arch= and remove lines after it if it ends with a \\. Replace with GPU_COMPUTE_CAPABILITY\n",
    "# makefile = re.sub(r'ARCH=(.*\\\\\\n)*.*', f'ARCH={GPU_COMPUTE_CAPABILITY}', makefile)\n",
    "\n",
    "\n",
    "# # Enable CUDNN_HALF if GPU compute capability >= 75\n",
    "# if int(GPU_COMPUTE_CAPABILITY) >= 75:\n",
    "#     makefile = re.sub(r'CUDNN_HALF=0', 'CUDNN_HALF=1', makefile)\n",
    "\n",
    "# with open('darknet/Makefile', 'w') as f:\n",
    "#     f.write(makefile)\n",
    "\n",
    "# # Build darknet\n",
    "# !(cd darknet && make -j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Upload video to colab\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# video_path = list(uploaded.keys())[0]\n",
    "\n",
    "video_path = \"../Videos/Img_1688.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading yolov4.conv.137...\n",
      "4.5.5\n"
     ]
    }
   ],
   "source": [
    "# if not os.path.exists(\"yolov4.weights\"):\n",
    "#   !curl https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4.weights -o yolov4.weights\n",
    "import requests\n",
    "required_files = {\n",
    "    \"yolov4.weights\": \"https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4.weights\",\n",
    "    \"yolov4.conv.137\": \"https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137\"\n",
    "}\n",
    "\n",
    "for file_name, url in required_files.items():\n",
    "    if os.path.exists(file_name):\n",
    "        continue\n",
    "    print(f\"Downloading {file_name}...\")\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    with open(file_name, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    print(f\"Downloaded {file_name}.\")\n",
    "\n",
    "\n",
    "# Load darknet dll\n",
    "import ctypes\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "print(cv2.__version__)\n",
    "import darknet.darknet as darknet\n",
    "\n",
    "\n",
    "# Load the network using opencv\n",
    "net = cv2.dnn.readNet(\"yolov4.weights\", \"darknet/cfg/yolov4.cfg\")\n",
    "classes = open(\"darknet/data/coco.names\").read().strip().split(\"\\n\")\n",
    "colors = np.random.uniform(0, 255, 1000000)\n",
    "\n",
    "\n",
    "# Set the backend to opencv\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "# Set the target to CUDA\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_OPENCL_FP16)\n",
    "font=cv2.FONT_HERSHEY_SIMPLEX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.__version__\n",
    "cv2.cuda.getCudaEnabledDeviceCount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [15], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m net\u001b[39m.\u001b[39msetInput(blob)\n\u001b[0;32m     14\u001b[0m output_layers_names \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39mgetUnconnectedOutLayersNames()\n\u001b[1;32m---> 15\u001b[0m layerOutputs \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39;49mforward(output_layers_names)\n\u001b[0;32m     16\u001b[0m boxes \u001b[39m=\u001b[39m []\n\u001b[0;32m     17\u001b[0m confidences \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Detect objects in the video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "# YoloV4 input size\n",
    "width = 416\n",
    "height = 416\n",
    "\n",
    "while True:\n",
    "    _, img = cap.read()\n",
    "    if img is None:\n",
    "        break\n",
    "    # img = cv2.resize(img, (width, height))\n",
    "    blob = cv2.dnn.blobFromImage(img, 1 / 255, (width, height), [0, 0, 0], 1, crop=False)\n",
    "    net.setInput(blob)\n",
    "    output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "    layerOutputs = net.forward(output_layers_names)\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "    for output in layerOutputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append((float(confidence)))\n",
    "                class_ids.append(class_id)\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    if len(indexes) > 0:\n",
    "        for i in indexes.flatten():\n",
    "            x, y, w, h = boxes[i]\n",
    "            # Convert coordinates to integers to image size\n",
    "            x = int(x * (img.shape[1] / width))\n",
    "            w = int(w * (img.shape[1] / width))\n",
    "            y = int(y * (img.shape[0] / height))\n",
    "            h = int(h * (img.shape[0] / height))\n",
    "            \n",
    "            label = str(classes[class_ids[i]])\n",
    "            confidence = str(round(confidences[i], 2))\n",
    "            color = colors[i]\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(img, label + \" \" + confidence, (x, y + 20), font, 1, color, 2)\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./generate_data.py --num-train-images 100000 --num-test-images 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to darknet format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use YOLOv4 to detect MNIST digits from images\n",
    "\n",
    "# Structure is train -> images -> 0,1,2,3,4,5,6,7,8,9 -> 0.jpg, 1.jpg, 2.jpg, ...\n",
    "# Structure is train -> labels -> 0,1,2,3,4,5,6,7,8,9 -> 0.txt, 1.txt, 2.txt, ...\n",
    "# Same for test\n",
    "\n",
    "data_path = os.path.join(os.getcwd(), 'MNIST-ObjectDetection/data/mnist_detection')\n",
    "train_path = os.path.join(data_path, 'train')\n",
    "test_path = os.path.join(data_path, 'test')\n",
    "\n",
    "cfg_path = os.path.join(os.getcwd(), 'cfg')\n",
    "os.makedirs(cfg_path, exist_ok=True)\n",
    "os.makedirs(\"darknet/backup\", exist_ok=True)\n",
    "\n",
    "# Train YOLOv4 on MNIST dataset\n",
    "# create data file\n",
    "with open(f'{cfg_path}/mnist.data', 'w') as f:\n",
    "    f.write(f'classes = 10\\n')\n",
    "    f.write(f'train = {cfg_path}/mnist_train.txt\\n')\n",
    "    f.write(f'valid = {cfg_path}/mnist_test.txt\\n')\n",
    "    f.write(f'names = {cfg_path}/mnist.names\\n')\n",
    "    f.write(f'backup = backup\\n')\n",
    "\n",
    "# create names file\n",
    "with open(f'{cfg_path}/mnist.names', 'w') as f:\n",
    "    for i in range(10):\n",
    "        f.write(str(i) + '\\n')\n",
    "\n",
    "# create train.txt file\n",
    "with open(f'{cfg_path}/mnist_train.txt', 'w') as f:\n",
    "    dirs = os.listdir(os.path.join(train_path, 'images'))\n",
    "    for d in dirs:\n",
    "        if d.endswith('.png'):\n",
    "            f.write(os.path.join(train_path, 'images', d) + '\\n')\n",
    "\n",
    "# create test.txt file\n",
    "with open(f'{cfg_path}/mnist_test.txt', 'w') as f:\n",
    "    dirs = os.listdir(os.path.join(test_path, 'images'))\n",
    "    for d in dirs:\n",
    "        if d.endswith('.png'):\n",
    "            f.write(os.path.join(test_path, 'images', d) + '\\n')\n",
    "\n",
    "# Moved all labels to the images folder\n",
    "# !mv MNIST-ObjectDetection/data/mnist_detection/train/labels/* MNIST-ObjectDetection/data/mnist_detection/train/images/\n",
    "# !mv MNIST-ObjectDetection/data/mnist_detection/test/labels/* MNIST-ObjectDetection/data/mnist_detection/test/images/\n",
    "\n",
    "\n",
    "# Train YOLOv4 on MNIST dataset\n",
    "# !./darknet/darknet.exe detector train MNIST-ObjectDetection/data/mnist.data MNIST-ObjectDetection/cfg/yolov4-mnist.cfg yolov4.conv.137 -dont_show -map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to darknet format\n",
    "# Original format is label,xmin,ymin,xmax,ymax and has a header\n",
    "# Darknet format is class x_center y_center width height and has no header\n",
    "\n",
    "import os\n",
    "\n",
    "def process_file(file, file_out):\n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()[1:]\n",
    "        res_lines = []\n",
    "        for line in lines:\n",
    "            label, xmin, ymin, xmax, ymax = line.strip().split(',')\n",
    "            x_center = (int(xmin) + int(xmax)) / 2\n",
    "            y_center = (int(ymin) + int(ymax)) / 2\n",
    "            width = int(xmax) - int(xmin)\n",
    "            height = int(ymax) - int(ymin)\n",
    "            res_lines.append(f'{label} {x_center} {y_center} {width} {height}\\n')\n",
    "    with open(file_out, 'w') as f:\n",
    "        f.writelines(res_lines)\n",
    "\n",
    "to_process = [\n",
    "    train_path,\n",
    "    test_path\n",
    "]\n",
    "\n",
    "for path in to_process:\n",
    "    print(f'Processing {path}')\n",
    "    for file in os.listdir(os.path.join(path, 'labels')):\n",
    "        if file.endswith('.txt'):\n",
    "            process_file(os.path.join(path, 'labels', file), os.path.join(path, 'images', file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects detected: 1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Open an image and detect objects\n",
    "config_path = os.path.join(os.getcwd(), './yolov4_custom.cfg')\n",
    "weights_path = \"C:/Users/aurel/ING3-DNN-Projet/yolov4.weights\"\n",
    "classes = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "net = cv2.dnn.readNetFromDarknet(config_path, weights_path)\n",
    "\n",
    "# Get the output layer names of the model\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers_names = net.getUnconnectedOutLayersNames() \n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread(\"C:/Users/aurel/ING3-DNN-Projet/23.png\")\n",
    "height = 416\n",
    "width = 416\n",
    "\n",
    "# Showing informations on the screen\n",
    "blob = cv2.dnn.blobFromImage(img, 1 / 255, (width, height), [0, 0, 0], 1, crop=False)\n",
    "net.setInput(blob)\n",
    "output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "layerOutputs = net.forward(output_layers_names)\n",
    "boxes = []\n",
    "confidences = []\n",
    "class_ids = []\n",
    "for output in layerOutputs:\n",
    "    for detection in output:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5:\n",
    "            center_x = int(detection[0] * width)\n",
    "            center_y = int(detection[1] * height)\n",
    "            w = int(detection[2] * width)\n",
    "            h = int(detection[3] * height)\n",
    "            x = int(center_x - w / 2)\n",
    "            y = int(center_y - h / 2)\n",
    "            boxes.append([x, y, w, h])\n",
    "            confidences.append((float(confidence)))\n",
    "            class_ids.append(class_id)\n",
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "print(f\"Number of objects detected: {len(indexes)}\")\n",
    "if len(indexes) > 0:\n",
    "    for i in indexes.flatten():\n",
    "        x, y, w, h = boxes[i]\n",
    "        # Convert coordinates to integers to image size\n",
    "        x = int(x * (img.shape[1] / width))\n",
    "        w = int(w * (img.shape[1] / width))\n",
    "        y = int(y * (img.shape[0] / height))\n",
    "        h = int(h * (img.shape[0] / height))\n",
    "        \n",
    "        label = str(classes[class_ids[i]])\n",
    "        confidence = str(round(confidences[i], 2))\n",
    "        color = colors[i]\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "        cv2.putText(img, label + \" \" + confidence, (x, y + 20), font, 1, color, 2)\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(10000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9', '81', '128', '127', '202']\n",
      "['0', '104', '83', '118', '99']\n",
      "['7', '30', '79', '69', '133']\n",
      "['0', '113', '129', '144', '168']\n",
      "['4', '51', '30', '87', '70']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [23], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m         cv2\u001b[39m.\u001b[39mputText(img, line[\u001b[39m0\u001b[39m], (x1, y1 \u001b[39m+\u001b[39m \u001b[39m20\u001b[39m), font, \u001b[39m1\u001b[39m, (\u001b[39m0\u001b[39m, \u001b[39m255\u001b[39m, \u001b[39m0\u001b[39m), \u001b[39m2\u001b[39m)\n\u001b[0;32m     22\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39mImage\u001b[39m\u001b[39m\"\u001b[39m, img)\n\u001b[1;32m---> 23\u001b[0m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m10000\u001b[39;49m)\n\u001b[0;32m     24\u001b[0m cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Show the image with its real bounding boxes\n",
    "img_path = \"./MNIST-ObjectDetection/data/mnist_detection/test/images/23.png\"\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "# Get the real bounding boxes\n",
    "with open(img_path.replace(\".png\", \".txt\"), \"r\") as f:\n",
    "    for line in f.readlines()[1:]:\n",
    "        line = line.strip().split(\",\")\n",
    "        print(line)\n",
    "        # x = int(float(line[1]) * img.shape[1])\n",
    "        # y = int(float(line[2]) * img.shape[0])\n",
    "        # w = int(float(line[3]) * img.shape[1])\n",
    "        # h = int(float(line[4]) * img.shape[0])\n",
    "        # cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        # cv2.putText(img, line[0], (x, y + 20), font, 1, (0, 255, 0), 2)\n",
    "        x1 = int(line[1])\n",
    "        y1 = int(line[2])\n",
    "        x2 = int(line[3])\n",
    "        y2 = int(line[4])\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(img, line[0], (x1, y1 + 20), font, 1, (0, 255, 0), 2)\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(10000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7dbd52f126c3f882a685d77ec02d1d98d7e11df31f3d9cf892855327d221452"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
