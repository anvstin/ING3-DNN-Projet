{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Object detection using YOLOv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git submodule update --init --recursive\n",
    "if not os.path.exists('MNIST-ObjectDetection/data'):\n",
    "    %pip install -r MNIST-ObjectDetection/requirements.txt\n",
    "    %cd MNIST-ObjectDetection\n",
    "    !python generate_data.py\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU_NAME =  str(os.popen('nvidia-smi --query-gpu=name --format=csv,noheader').read()).strip()\n",
    "# GPU_COMPUTE_CAPABILITY = str(os.popen('nvidia-smi --query-gpu=compute_cap --format=csv,noheader').read()).strip()\n",
    "# # Remove newlines\n",
    "# GPU_COMPUTE_CAPABILITY = GPU_COMPUTE_CAPABILITY.replace('.', '')\n",
    "\n",
    "# print(f'GPU_NAME: {GPU_NAME}')\n",
    "# print(f'GPU_COMPUTE_CAPABILITY: {GPU_COMPUTE_CAPABILITY}')\n",
    "# # Build using make, enable OpenCV and CUDNN\n",
    "# import re\n",
    "# with open('darknet/Makefile', 'r') as f:\n",
    "#     makefile = f.read()\n",
    "# makefile = re.sub(r'GPU=0', 'GPU=1', makefile)\n",
    "# makefile = re.sub(r'CUDNN=0', 'CUDNN=1', makefile)\n",
    "# makefile = re.sub(r'CUDNN_HALF=0', 'CUDNN_HALF=1', makefile)\n",
    "# makefile = re.sub(r'OPENCV=0', 'OPENCV=1', makefile)\n",
    "\n",
    "# # Remove everything in arch= and remove lines after it if it ends with a \\. Replace with GPU_COMPUTE_CAPABILITY\n",
    "# makefile = re.sub(r'ARCH=(.*\\\\\\n)*.*', f'ARCH={GPU_COMPUTE_CAPABILITY}', makefile)\n",
    "\n",
    "\n",
    "# # Enable CUDNN_HALF if GPU compute capability >= 75\n",
    "# if int(GPU_COMPUTE_CAPABILITY) >= 75:\n",
    "#     makefile = re.sub(r'CUDNN_HALF=0', 'CUDNN_HALF=1', makefile)\n",
    "\n",
    "# with open('darknet/Makefile', 'w') as f:\n",
    "#     f.write(makefile)\n",
    "\n",
    "# # Build darknet\n",
    "# !(cd darknet && make -j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Upload video to colab\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# video_path = list(uploaded.keys())[0]\n",
    "\n",
    "video_path = \"../Videos/Img_1688.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5.5\n"
     ]
    }
   ],
   "source": [
    "# if not os.path.exists(\"yolov4.weights\"):\n",
    "#   !curl https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4.weights -o yolov4.weights\n",
    "\n",
    "# Load darknet dll\n",
    "import ctypes\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "print(cv2.__version__)\n",
    "import darknet.darknet as darknet\n",
    "\n",
    "\n",
    "# Load the network using opencv\n",
    "net = cv2.dnn.readNet(\"yolov4.weights\", \"darknet/cfg/yolov4.cfg\")\n",
    "classes = open(\"darknet/data/coco.names\").read().strip().split(\"\\n\")\n",
    "colors = np.random.uniform(0, 255, 1000000)\n",
    "\n",
    "\n",
    "# Set the backend to opencv\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "# Set the target to CUDA\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_OPENCL_FP16)\n",
    "font=cv2.FONT_HERSHEY_SIMPLEX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.__version__\n",
    "cv2.cuda.getCudaEnabledDeviceCount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [15], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m net\u001b[39m.\u001b[39msetInput(blob)\n\u001b[0;32m     14\u001b[0m output_layers_names \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39mgetUnconnectedOutLayersNames()\n\u001b[1;32m---> 15\u001b[0m layerOutputs \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39;49mforward(output_layers_names)\n\u001b[0;32m     16\u001b[0m boxes \u001b[39m=\u001b[39m []\n\u001b[0;32m     17\u001b[0m confidences \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Detect objects in the video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "# YoloV4 input size\n",
    "width = 416\n",
    "height = 416\n",
    "\n",
    "while True:\n",
    "    _, img = cap.read()\n",
    "    if img is None:\n",
    "        break\n",
    "    # img = cv2.resize(img, (width, height))\n",
    "    blob = cv2.dnn.blobFromImage(img, 1 / 255, (width, height), [0, 0, 0], 1, crop=False)\n",
    "    net.setInput(blob)\n",
    "    output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "    layerOutputs = net.forward(output_layers_names)\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "    for output in layerOutputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append((float(confidence)))\n",
    "                class_ids.append(class_id)\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    if len(indexes) > 0:\n",
    "        for i in indexes.flatten():\n",
    "            x, y, w, h = boxes[i]\n",
    "            # Convert coordinates to integers to image size\n",
    "            x = int(x * (img.shape[1] / width))\n",
    "            w = int(w * (img.shape[1] / width))\n",
    "            y = int(y * (img.shape[0] / height))\n",
    "            h = int(h * (img.shape[0] / height))\n",
    "            \n",
    "            label = str(classes[class_ids[i]])\n",
    "            confidence = str(round(confidences[i], 2))\n",
    "            color = colors[i]\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(img, label + \" \" + confidence, (x, y + 20), font, 1, color, 2)\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use YOLOv4 to detect MNIST digits from images\n",
    "\n",
    "# Structure is train -> images -> 0,1,2,3,4,5,6,7,8,9 -> 0.jpg, 1.jpg, 2.jpg, ...\n",
    "# Structure is train -> labels -> 0,1,2,3,4,5,6,7,8,9 -> 0.txt, 1.txt, 2.txt, ...\n",
    "# Same for test\n",
    "\n",
    "data_path = 'MNIST-ObjectDetection/data/mnist_detection'\n",
    "train_path = os.path.join(data_path, 'train')\n",
    "test_path = os.path.join(data_path, 'test')\n",
    "\n",
    "# Train YOLOv4 on MNIST dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7dbd52f126c3f882a685d77ec02d1d98d7e11df31f3d9cf892855327d221452"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
